# ğŸ¬ Sunum iÃ§in Komutlar - HÄ±zlÄ± Referans

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Sunum Ã–ncesi HazÄ±rlÄ±k)

```bash
# 1. Production stack'i baÅŸlat
./scripts/start_production.sh

# 2. TarayÄ±cÄ±da ÅŸu sekmeleri aÃ§:
# http://localhost:8000/docs     (API)
# http://localhost:3000           (Grafana - admin/admin)
# http://localhost:9090           (Prometheus)
# http://localhost:5000           (MLflow)
```

---

## ğŸ“Š Demo 1: Model EÄŸitimi & Metrikler

### GeliÅŸtirilmiÅŸ Metriklerle EÄŸitim
```bash
python -m src.training.trainer
```

**GÃ¶stereceÄŸiniz metrikler:**
- âœ… MAE (Mean Absolute Error)
- âœ… RMSE (Root Mean Squared Error)
- âœ… MAPE (Mean Absolute Percentage Error)
- âœ… RÂ² Score (Coefficient of Determination)
- âœ… MedAE (Median Absolute Error)
- âœ… Bias (Overestimation/Underestimation)
- âœ… Within Â±5 trips accuracy
- âœ… Within Â±10% accuracy

---

## ğŸ† Demo 2: Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

### 3 Model Baseline Comparison
```bash
python -m src.training.model_comparison
```

**KarÅŸÄ±laÅŸtÄ±rÄ±lan modeller:**
- XGBoost (Current)
- LightGBM (Alternative)
- CatBoost (Alternative)

**SonuÃ§:** Tablo formatÄ±nda tÃ¼m metriklerde karÅŸÄ±laÅŸtÄ±rma + winner

### MLflow UI
```bash
mlflow ui
# http://localhost:5000
```

**MLflow'da gÃ¶stereceÄŸiniz:**
- TÃ¼m experiment runs
- Metric comparison charts
- Model parameters
- Best model selection

---

## ğŸ”¥ Demo 3: Real-time Streaming Dashboard (EN ETKÄ°LEYÄ°CÄ°!)

### Dashboard'u BaÅŸlat
```bash
./scripts/demo_dashboard.sh
# veya
streamlit run src/dashboard/realtime_dashboard.py
# http://localhost:8501
```

### Mode 1: Manual Input
1. DeÄŸerleri manuel gir
2. "Make Prediction" butonuna tÄ±kla
3. SonuÃ§larÄ± gÃ¶ster

### Mode 2: Auto Simulation â­â­â­
1. "Auto Simulation" seÃ§
2. Speed: 3-5 predictions/sec
3. Max predictions: 40-50
4. "Start Simulation" â†’ **CANLI GRAFÄ°KLERÄ° Ä°ZLET!**

**CanlÄ± grafiklerde gÃ¶stereceÄŸiniz:**
- âœ… Prediction vs Actual (time series)
- âœ… Error over time (error chart)
- âœ… Demand distribution (histogram)
- âœ… Live MAE/RMSE updates

**Bu Ã§ok etkileyici olacak!** ğŸ¯

---

## ğŸ—½ Demo 3B: NYC Map Dashboard â­â­â­ (YENÄ° - Ã‡OK ETKÄ°LEYÄ°CÄ°!)

### Dashboard'u BaÅŸlat
```bash
./scripts/start_map_dashboard.sh
# http://localhost:8501
```

**4 FarklÄ± GÃ¶rselleÅŸtirme Modu:**

### 1. Demand Heatmap ğŸ”¥
- NYC haritasÄ± Ã¼zerinde location-based demand
- 60+ Manhattan lokasyonu + airports
- Hover ile her location iÃ§in detay
- Saat bazlÄ± demand deÄŸiÅŸimi
- Top 10 en yoÄŸun lokasyonlar listesi

### 2. Live Predictions ğŸ”®
- TÃ¼m NYC lokasyonlarÄ± iÃ§in real-time tahmin
- API ile entegre predictions
- Harita Ã¼zerinde tahmin deÄŸerleri (bubble size)
- Interactive Plotly visualization

### 3. Drift Analysis ğŸ”
- Son drift raporlarÄ±nÄ± harita Ã¼zerinde gÃ¶ster
- Lokasyon bazlÄ± drift analizi

### 4. Comparison âš–ï¸
- Predicted vs Actual scatter plot
- Location-based karÅŸÄ±laÅŸtÄ±rma
- Perfect prediction line ile comparison

**Ek Features:**
- ğŸ“Š Analytics tab: Hourly demand trends, top locations
- ğŸ“ˆ Time Series tab: Location-specific demand patterns
- ğŸ—ºï¸ Borough filtering (Manhattan, Queens, Brooklyn, Bronx)

**Bu MUTlaka gÃ¶sterin!** ğŸ—½ğŸ”¥
- Interactive NYC haritasÄ±
- Real-time visualization
- Professional gÃ¶rÃ¼nÃ¼m
- Taksi projesi iÃ§in perfect!

---

## ğŸ“Š Demo 3C: MLOps Monitoring Dashboard â­â­â­ (YENÄ°!)

### Dashboard'u BaÅŸlat
```bash
./scripts/start_monitoring_dashboard.sh
# http://localhost:8502 (farklÄ± port!)
```

**4 Ana Tab:**

### 1. Overview ğŸ 
- Current model version & MAE
- Total models & improvement trends
- Recent model versions table
- Recent alerts

### 2. Continual Learning ğŸ”„
- Check timeline (color-coded status)
- Retraining events statistics
- Latest check report details
- A/B testing results
- Performance metrics comparison

### 3. Drift Detection ğŸ“‰
- Latest drift status (detected/stable)
- Drift heatmap (features x dates)
- Feature-level drift analysis table
- KS statistics, P-values, PSI scores

### 4. Model Performance ğŸ“Š
- Performance trends (MAE, RMSE, RÂ² over time)
- Model version timeline
- Model comparison table
- All models side-by-side

**Bu monitoring dashboard Ã§ok professional!** ğŸ“ˆ
- Web-based continual learning monitoring
- Drift detection visualization
- Model performance tracking
- Production-ready dashboard

---

## ğŸŒ Demo 4: API & Swagger UI

### Swagger UI'da Test
```
http://localhost:8000/docs
```

### Test Endpoints:
1. **GET /health** - Health check
2. **GET /model/info** - Model bilgileri
3. **POST /predict** - Single prediction

Example request:
```json
{
  "PULocationID": 237,
  "hour": 18,
  "day_of_week": 4,
  "month": 6,
  "lag_1": 15.0,
  "lag_4": 18.0,
  "lag_96": 20.0,
  "rolling_mean_4": 16.5
}
```

4. **POST /predict/batch** - Batch prediction

---

## ğŸ“ˆ Demo 5: Prometheus & Grafana

### Prometheus Metrics
```
http://localhost:8000/metrics
```

**Query Ã¶rnekleri (Prometheus UI - http://localhost:9090):**
```promql
# Request rate
rate(taxi_predictions_total{status="success"}[5m])

# P95 Latency
histogram_quantile(0.95, rate(taxi_prediction_latency_seconds_bucket[5m]))

# Active requests
taxi_active_requests
```

### Grafana Dashboard
```
http://localhost:3000
Login: admin / admin
```

**Dashboard'da gÃ¶stereceÄŸiniz:**
- Request rate & success rate
- Latency percentiles (p50, p95, p99)
- Prediction distribution
- Error rates
- Active requests gauge

---

## ğŸ” Demo 6: Drift Detection

### Drift Analysis Ã‡alÄ±ÅŸtÄ±r
```bash
./scripts/run_drift_check.sh
# veya
python -m src.monitoring.run_drift_detection --days-back 7
```

**GÃ¶stereceÄŸiniz:**
- Feature-by-feature drift analysis
- KS test p-values
- PSI scores
- Distribution shifts (mean, std)
- Drift detected features

**Rapor:**
```bash
cat monitoring/drift_reports/drift_report_*.json | jq '.'
```

---

## ğŸ”„ Demo 7: Continual Learning Pipeline â­â­â­ (EN YENÄ°!)

### Quick Demo (4 hafta simÃ¼lasyon)
```bash
python -m src.continual_learning.demo_continual_learning --weeks 4
```

**GÃ¶stereceÄŸiniz:**
- ğŸ“Š HaftalÄ±k performance monitoring
- ğŸ” Drift detection (KS test, PSI)
- ğŸš¨ Automatic retraining triggers
- ğŸ† A/B testing (old vs new model)
- ğŸš€ Automated deployment
- ğŸ“ˆ Model versioning & registry

**Demo akÄ±ÅŸÄ±:**
1. Her hafta iÃ§in production data yÃ¼klenir
2. Performance metrics hesaplanÄ±r (MAE, RMSE, RÂ²)
3. Drift detection yapÄ±lÄ±r (2024 train vs 2025 prod)
4. Retraining gerekirse:
   - Yeni model eÄŸitilir
   - A/B test yapÄ±lÄ±r
   - Daha iyi model deploy edilir

### Production Continual Learning Check
```bash
# Last 7 days check
./scripts/run_continual_learning.sh --days-back 7

# Dry run (don't deploy)
./scripts/run_continual_learning.sh --days-back 7 --dry-run

# Force retrain
./scripts/run_continual_learning.sh --force

# Specific date
./scripts/run_continual_learning.sh --days-back 7 --end-date 2025-01-15
```

**GÃ¶stereceÄŸiniz:**
- Real-world continual learning check
- Performance degradation detection
- Drift-triggered retraining
- Model comparison & deployment decision
- JSON reports (monitoring/continual_learning_reports/)

**Bu Ã§ok etkileyici olacak!** ğŸ”¥
- Otomatik model monitoring
- Drift detection ile proactive retraining
- A/B testing ile safe deployment
- Full MLOps lifecycle

---

## ğŸ“Š Demo 8: Streaming Simulation (Original)

### Klasik Streaming Demo
```bash
./demo_stream.sh
```

**GÃ¶stereceÄŸiniz:**
- 100 kayÄ±tlÄ±k simulation
- Real-time request/response
- MAE/RMSE hesaplama
- Terminal-based output

---

## ğŸ”§ Demo 9: Monitoring & Health Checks

### Metrics Check
```bash
./scripts/check_metrics.sh
```

**GÃ¶stereceÄŸiniz:**
- API health status
- Model info
- Current metrics snapshot
- Service status

### Docker Services
```bash
docker-compose -f docker-compose.prod.yml ps
```

---

## ğŸ¯ Demo SÄ±rasÄ± (25-30 dakika)

```
1. GiriÅŸ & Problem (2 dk)
   â””â”€> Slides

2. Model Training (4 dk)
   â””â”€> python -m src.training.trainer
   â””â”€> python -m src.training.model_comparison
   â””â”€> mlflow ui

3. Real-time Dashboard â­ (6 dk)
   â””â”€> ./scripts/demo_dashboard.sh
   â””â”€> Auto simulation Ã§alÄ±ÅŸtÄ±r
   â””â”€> Live graphs gÃ¶ster

4. API Demo (3 dk)
   â””â”€> Swagger UI
   â””â”€> /predict test
   â””â”€> /metrics gÃ¶ster

5. Monitoring (3 dk)
   â””â”€> Prometheus queries
   â””â”€> Grafana dashboard

6. Drift Detection (2 dk)
   â””â”€> ./scripts/run_drift_check.sh
   â””â”€> Results explain

7. Continual Learning â­â­â­ (6 dk) - EN ETKÄ°LEYÄ°CÄ°!
   â””â”€> python -m src.continual_learning.demo_continual_learning --weeks 4
   â””â”€> HaftalÄ±k monitoring gÃ¶ster
   â””â”€> Retraining triggers
   â””â”€> A/B testing & deployment

8. Production Setup (2 dk)
   â””â”€> Docker Compose
   â””â”€> Services overview

9. Q&A (3-5 dk)
```

---

## ğŸ—£ï¸ SÃ¶yleyebileceÄŸiniz Åeyler

### Model Performance:
```
"Modelimiz comprehensive metrics ile evaluate edildi.
MAE 3.28 ile mÃ¼kemmel performans gÃ¶steriyor.
RÂ² score ile tahmin gÃ¼cÃ¼mÃ¼z de oldukÃ§a gÃ¼Ã§lÃ¼.
Tahminlerimizin %X'i Â±5 trip hata payÄ± iÃ§inde."
```

### Model Comparison:
```
"3 farklÄ± gradient boosting algoritmasÄ±nÄ± karÅŸÄ±laÅŸtÄ±rdÄ±k.
XGBoost, LightGBM ve CatBoost'u aynÄ± hiperparametrelerle eÄŸittik.
SonuÃ§lar tabloda gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi, [model] en iyi performansÄ± gÃ¶sterdi."
```

### Real-time Dashboard:
```
"Åimdi en etkileyici kÄ±smÄ± gÃ¶relim: Real-time streaming dashboard.
Burada gerÃ§ek 2025 production verisini kullanarak
canlÄ± tahminler yapÄ±yoruz.
Grafiklerde predicted vs actual'i anlÄ±k olarak gÃ¶rebilirsiniz.
MAE ve RMSE deÄŸerleri her tahminle birlikte gÃ¼ncelleniyor."
```

### Drift Detection:
```
"Production'da model drift Ã¶nemli bir risk.
2024 training verisi ile 2025 production verisini
istatistiksel testlerle karÅŸÄ±laÅŸtÄ±rÄ±yoruz.
KS test ve PSI ile distribution shift'leri tespit ediyoruz."
```

### Production Monitoring:
```
"Tam bir MLOps pipeline kurduk.
Prometheus ile metrikleri topluyoruz,
Grafana ile visualize ediyoruz,
Alert kurallarÄ±yla proaktif monitoring yapÄ±yoruz.
Her ÅŸey production-ready."
```

### Continual Learning:
```
"En Ã¶nemli Ã¶zelliÄŸimiz: Continual Learning Pipeline.
Production'da model performansÄ± sÃ¼rekli izleniyor.
Her hafta otomatik olarak:
  - Performance metrics kontrol ediliyor (MAE threshold)
  - Data drift detection yapÄ±lÄ±yor (KS test, PSI)
  - EÄŸer drift veya performance degradation varsa,
    otomatik olarak model yeniden eÄŸitiliyor.
  - A/B testing ile eski ve yeni model karÅŸÄ±laÅŸtÄ±rÄ±lÄ±yor.
  - Daha iyi olan model otomatik deploy ediliyor.

Åimdi 4 haftalÄ±k bir simÃ¼lasyon gÃ¶steriyorum.
Her hafta iÃ§in drift check yapÄ±yor, gerekirse retrain ediyor.
Bu tam otomatik, human-in-the-loop yok.
GerÃ§ek bir MLOps production sistemi!"
```

---

## ğŸ“Œ Ã–nemli Notlar

### Sunum Ã–ncesi Checklist:
- [ ] Production stack Ã§alÄ±ÅŸÄ±yor
- [ ] TÃ¼m servisler healthy
- [ ] Data dosyalarÄ± yerinde
- [ ] Requirements install edildi
- [ ] TarayÄ±cÄ± sekmeleri aÃ§Ä±k
- [ ] Terminal'ler hazÄ±r

### EÄŸer Bir Åey Ã‡alÄ±ÅŸmazsa:
```bash
# Servisleri restart et
docker-compose -f docker-compose.prod.yml restart

# API'yi tek baÅŸÄ±na baÅŸlat
./start_api.sh

# LoglarÄ± kontrol et
docker logs taxi-prediction-api
```

---

## ğŸ¬ Final Kontrol

**5 dakika Ã¶nce:**
1. Production stack Ã§alÄ±ÅŸÄ±yor mu? âœ“
2. Dashboard aÃ§Ä±lÄ±yor mu? âœ“
3. MLflow UI eriÅŸilebilir mi? âœ“
4. Grafana aÃ§Ä±lÄ±yor mu? âœ“
5. API Swagger UI Ã§alÄ±ÅŸÄ±yor mu? âœ“

**BaÅŸarÄ±lar!** ğŸš€

---

## ğŸ”¥ Pro Tips

1. **Real-time dashboard'u muhakkahazÄ±rlÄ±k gÃ¶ster!** En etkileyici kÄ±sÄ±m.

2. **Model comparison'da tabloyu bÃ¼yÃ¼k font ile gÃ¶ster.** Winner belli olsun.

3. **Grafana dashboard'da refresh rate'i 5 saniye yap.** CanlÄ± gÃ¶rÃ¼nsÃ¼n.

4. **Terminal font size'Ä± bÃ¼yÃ¼t.** Herkes gÃ¶rsÃ¼n.

5. **Demo sÄ±rasÄ±nda API'nin response time'Ä±nÄ± vurgula.** HÄ±zlÄ±!

6. **MAE/RMSE deÄŸerlerini yorumla.** "Sadece 3-4 yolcu hata!"

7. **Production stack'i gÃ¶sterirken "tek komutla 6 servis" vurgula.**

8. **Drift detection sonuÃ§larÄ±nÄ± yorumla.** Teknik detaya girme.

9. **MLflow'da experiment comparison'Ä± grafik olarak gÃ¶ster.**

10. **Soru gelirse hazÄ±r ol:** Metrics, model choice, deployment strategy

---

**HazÄ±rsÄ±n! BaÅŸarÄ±lar!** ğŸ¯âœ¨
